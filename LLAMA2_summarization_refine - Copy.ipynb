{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install awq_inference_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\theot\\Anaconda3\\envs\\llama2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\t\n",
    "import transformers\n",
    "from transformers import AutoTokenizer\n",
    "from langchain import LLMChain, HuggingFacePipeline, PromptTemplate\n",
    "\n",
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.schema import Document\n",
    "\n",
    "## import automodelforcausallm \n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "##from autogptq importGPTQConfig \n",
    "# import awq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.47s/it]\n",
      "c:\\Users\\theot\\Anaconda3\\envs\\llama2\\Lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, token ='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' ) \n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "# gptq_config = GPTQConfig(bits=4, dataset = \"c4\", tokenizer=tokenizer)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=gptq_config)\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"cuda:0\",\n",
    "    max_length=4096,\n",
    "    do_sample=True,\n",
    "\t# load_in_8\n",
    "    top_k=10,\n",
    "    num_return_sequences=1,\n",
    "\tmax_new_tokens=4000,\n",
    "\tmin_new_tokens=10,\n",
    "\tbatch_size=1,\n",
    "\ttoken = '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'\n",
    "    # eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipeline, model_kwargs = {'temperature':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As we celebrate the culmination of our ambitious environmental sustainability goal—to achieve a 10% reduction in our carbon footprint—I am thrilled to present a comprehensive report detailing the quantitative achievements and the strategic initiatives that led to our success.\n",
      "\n",
      "1. Electric Vehicles (EVs):\n",
      "Our transition to electric vehicles has been nothing short of transformative. By replacing 75% of our traditional fleet with electric vehicles, we achieved a remarkable 30% reduction in direct carbon emissions related to corporate transportation. This transition, coupled with the installation of 50 EV charging stations across our office locations, not only lowered our carbon footprint but also demonstrated a commitment to cutting-edge sustainable technologies.\n",
      "\n",
      "2. Solar Energy Integration:\n",
      "The deployment of solar panels on the rooftops of our key facilities played a pivotal role in reshaping our energy landscape. These solar installations contributed to a 20% reduction in our overall energy consumption, with an annual generation of 1.5 gigawatt-hours of clean energy. This translates to an equivalent reduction of 1,200 metric tons of CO2 annually, showcasing the tangible impact of our renewable energy initiatives.\n",
      "\n",
      "3. Employee Engagement and Training:\n",
      "Our commitment to employee engagement bore fruit in more ways than one. Through targeted training programs, we observed a 15% decrease in individual energy consumption across our workforce. Additionally, waste reduction initiatives led to a 25% decrease in overall office waste generation. These statistics underscore the importance of fostering a culture of sustainability within the organization and the direct correlation between employee awareness and environmentally responsible behavior.\n",
      "\n",
      "4. Collaborative Partnerships:\n",
      "Engaging in collaborative partnerships yielded noteworthy results. By participating in industry-wide initiatives and aligning with environmental organizations, we leveraged shared resources and expertise to achieve a 10% reduction in supply chain emissions. This collaboration also facilitated knowledge exchange, enabling us to implement best practices that further enhanced our environmental performance.\n",
      "\n",
      "5. Financial Impact:\n",
      "Beyond the environmental benefits, our sustainability initiatives have had positive financial implications. The integration of energy-efficient technologies resulted in a 15% reduction in our annual energy costs. The adoption of sustainable practices in our supply chain contributed to an overall 8% reduction in operational expenses, showcasing the dual impact of our efforts on both environmental and financial sustainability.\n",
      "\n",
      "Looking Forward:\n",
      "As we bask in the success of achieving our initial environmental sustainability goal, it is imperative to acknowledge that this is just the beginning. Building on our achievements, we are setting our sights on more ambitious targets, including a further 15% reduction in carbon emissions over the next fiscal year. The data-driven insights from our achievements serve as a roadmap for future initiatives, guiding us toward even greater sustainability milestones.\n",
      "\n",
      "In conclusion, the numbers speak volumes about the success of our environmental sustainability endeavors. Through a strategic combination of electrification, renewable energy integration, employee engagement, and collaborative partnerships, we have not only met but exceeded our carbon reduction targets. This report serves not only as a record of our achievements but as a catalyst for future endeavors, reinforcing our commitment to sustainable business practices and our role as stewards of the environment. As we continue this journey, the integration of data-driven insights will remain paramount, guiding us toward a future where environmental sustainability is not just a goal but a fundamental aspect of our corporate identity.\n"
     ]
    }
   ],
   "source": [
    "texts = []\n",
    "for i in range(7):\n",
    "\twith open(f'./text/text{i+1}.txt', 'r') as file:\n",
    "\t\tt = file.read()\n",
    "\ttexts.append(t)\n",
    "\n",
    "\n",
    "docs = [\n",
    "\tDocument(\n",
    "\t\tpage_content=t\n",
    "\t) for t in texts\n",
    "]\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=4000) and `max_length`(=4096) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RefineDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mWrite a report of the following:\n",
      "As we celebrate the culmination of our ambitious environmental sustainability goal—to achieve a 10% reduction in our carbon footprint—I am thrilled to present a comprehensive report detailing the quantitative achievements and the strategic initiatives that led to our success.\n",
      "\n",
      "1. Electric Vehicles (EVs):\n",
      "Our transition to electric vehicles has been nothing short of transformative. By replacing 75% of our traditional fleet with electric vehicles, we achieved a remarkable 30% reduction in direct carbon emissions related to corporate transportation. This transition, coupled with the installation of 50 EV charging stations across our office locations, not only lowered our carbon footprint but also demonstrated a commitment to cutting-edge sustainable technologies.\n",
      "\n",
      "2. Solar Energy Integration:\n",
      "The deployment of solar panels on the rooftops of our key facilities played a pivotal role in reshaping our energy landscape. These solar installations contributed to a 20% reduction in our overall energy consumption, with an annual generation of 1.5 gigawatt-hours of clean energy. This translates to an equivalent reduction of 1,200 metric tons of CO2 annually, showcasing the tangible impact of our renewable energy initiatives.\n",
      "\n",
      "3. Employee Engagement and Training:\n",
      "Our commitment to employee engagement bore fruit in more ways than one. Through targeted training programs, we observed a 15% decrease in individual energy consumption across our workforce. Additionally, waste reduction initiatives led to a 25% decrease in overall office waste generation. These statistics underscore the importance of fostering a culture of sustainability within the organization and the direct correlation between employee awareness and environmentally responsible behavior.\n",
      "\n",
      "4. Collaborative Partnerships:\n",
      "Engaging in collaborative partnerships yielded noteworthy results. By participating in industry-wide initiatives and aligning with environmental organizations, we leveraged shared resources and expertise to achieve a 10% reduction in supply chain emissions. This collaboration also facilitated knowledge exchange, enabling us to implement best practices that further enhanced our environmental performance.\n",
      "\n",
      "5. Financial Impact:\n",
      "Beyond the environmental benefits, our sustainability initiatives have had positive financial implications. The integration of energy-efficient technologies resulted in a 15% reduction in our annual energy costs. The adoption of sustainable practices in our supply chain contributed to an overall 8% reduction in operational expenses, showcasing the dual impact of our efforts on both environmental and financial sustainability.\n",
      "\n",
      "Looking Forward:\n",
      "As we bask in the success of achieving our initial environmental sustainability goal, it is imperative to acknowledge that this is just the beginning. Building on our achievements, we are setting our sights on more ambitious targets, including a further 15% reduction in carbon emissions over the next fiscal year. The data-driven insights from our achievements serve as a roadmap for future initiatives, guiding us toward even greater sustainability milestones.\n",
      "\n",
      "In conclusion, the numbers speak volumes about the success of our environmental sustainability endeavors. Through a strategic combination of electrification, renewable energy integration, employee engagement, and collaborative partnerships, we have not only met but exceeded our carbon reduction targets. This report serves not only as a record of our achievements but as a catalyst for future endeavors, reinforcing our commitment to sustainable business practices and our role as stewards of the environment. As we continue this journey, the integration of data-driven insights will remain paramount, guiding us toward a future where environmental sustainability is not just a goal but a fundamental aspect of our corporate identity.\n",
      "REPORT:\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## refine \n",
    "prompt_template = \"\"\"Write a report of the following:\n",
    "{text}\n",
    "REPORT:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "refine_template = (\n",
    "    \"Your job is to produce a final report in paragraph form\\n\"\n",
    "    \"We have provided an existing report up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine or add to the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"If the context isn't useful, you must return the original summary, unchanged\\n\"\n",
    "\t\"REFINED REPORT(or UNCHANGED REPORT):\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)\n",
    "refine_chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    "\tverbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "refined_summary = refine_chain({\"input_documents\": [docs[0],docs[1],docs[2],docs[3]]})##refine_chain.run([docs[0],docs[1]])\n",
    "print(refined_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['input_documents', 'intermediate_steps', 'output_text'])\n"
     ]
    }
   ],
   "source": [
    "print(refined_summary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "* Transitioned 75% of traditional fleet to electric vehicles, resulting in a 30% reduction in direct carbon emissions\n",
      "* Deployed solar panels on rooftops, contributing to a 20% reduction in overall energy consumption and 1,200 metric tons of CO2 reduction annually\n",
      "* Fostered a culture of sustainability through targeted training programs, resulting in a 15% decrease in individual energy consumption across the workforce\n",
      "* Collaborated with industry partners to achieve a 10% reduction in supply chain emissions\n",
      "* Achieved a 15% reduction in annual energy costs and an 8% reduction in operational expenses\n",
      "* Set sights on more ambitious targets, including a further 15% reduction in carbon emissions over the next fiscal year.\n",
      "-------------\n",
      "\n",
      "\n",
      "Please provide the actual summary you would like to refine or add to, and I will assist you in producing a polished and coherent final report.\n"
     ]
    }
   ],
   "source": [
    "print(refined_summary['intermediate_steps'][0])\n",
    "print('-------------')\n",
    "print(refined_summary['intermediate_steps'][1])\n",
    "# print(refined_summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please select one of the options below. \n"
     ]
    }
   ],
   "source": [
    "print(refined_summary['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## first work on the merge chain because we can do it locally.\n",
    "\n",
    "## things to improve: \n",
    "\n",
    "# 1. there are llama2 models that are finetuned and adapted for 32K+ contexts\n",
    "# https://huggingface.co/NousResearch/Yarn-Llama-2-7b-128k\n",
    "\n",
    "# 1. we should try the merge summarize chain and/or change the prompt of the refine chain\n",
    "\n",
    "\n",
    "\n",
    "# 2. it may be possible that there are too many context tokens and thus we are not able to generate the summary.\n",
    "\n",
    "\n",
    "\n",
    "# the summaries are about 1K tokens so I don't think that should be the issue\n",
    "# -- other people are also getting the same error"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
